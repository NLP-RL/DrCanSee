# Dr. Can See: Towards a Multi-modal Disease Diagnosis Virtual Assistant

The repository contains code for research article titled 'Dr. Can See: Towards a Multi-modal Disease Diagnosis Virtual Assistant' published at 31st ACM International Conference on Information and Knowledge Management (CIKM 2022).

### Abstract: 

Artificial Intelligence-based clinical decision support is gaining ever-growing popularity and demand in both the research and industry communities. One such manifestation is automatic disease diagnosis, which aims to assist clinicians in conducting symptom investigation and disease diagnosis. When we consult with doctors, we often report and describe our health conditions with visual aids. Moreover, many people are unacquainted with several symptoms and medical terms, such as mouth ulcer and skin growth. Therefore, visual form of symptom reporting is more of a necessity. However, existing disease diagnosis assistants fail to consider signs/symptoms from visual aid, and they rely solely on symptom information extracted through text responses. Motivated by the efficacy of visual form of symptom reporting, we propose and build a novel end-to-end Multimodal Disease Diagnosis Virtual Assistant (MDD-VA) using reinforcement learning technique. In conversation, users' responses are heavily influenced by the ongoing dialogue context, and multimodal responses appear to be of no difference. We also propose and incorporate a Context-aware Symptom Image Identification module that leverages discourse context in addition to the symptom image for identifying symptoms effectively. Furthermore, we first curate a multimodal conversational medical dialogue corpus in English that is annotated with intent, symptoms, and visual information. The proposed MDD-VA outperforms multiple uni-modal baselines in both automatic and human evaluation, which firmly establishes the critical role of symptom information provided by visuals.

![Working](https://github.com/NLP-RL/DrCanSee/blob/main/Dr-Can-See.png)

#### Full Paper: https://www.cse.iitb.ac.in/~pb/papers/cikm22-dr-see.pdf

### Access to the Dataset

We provide the dataset for research and academic purposes. To request access to the dataset, please follow the instructions below:

1. **Fill Out the Request Form**: To access the dataset, you need to submit a request through our [Google Form](https://forms.gle/C5q7jDprPGsCuYcD6).

2. **Review and Approval**: After submitting the form, your request will be reviewed. If approved, you will receive an email with a link to download the dataset.

3. **Terms of Use**: By requesting access, you agree to:
    - Use the dataset solely for non-commercial, educational, and research purposes.
    - Not use the dataset for any commercial activities.
    - Attribute the creators of this resource in any works (publications, presentations, or other public dissemination) utilizing the dataset.
    - Not disseminate the dataset without prior permission from the appropriate authorities.

### Citation Information 
If you find this code useful in your research, please consider citing:
~~~~
@inproceedings{tiwari2022dr,
  title={Dr. can see: towards a multi-modal disease diagnosis virtual assistant},
  author={Tiwari, Abhisek and Manthena, Manisimha and Saha, Sriparna and Bhattacharyya, Pushpak and Dhar, Minakshi and Tiwari, Sarbajeet},
  booktitle={Proceedings of the 31st ACM international conference on information \& knowledge management},
  pages={1935--1944},
  year={2022}
}


Please contact us @ abhisektiwari2014@gmail.com for any questions, suggestions, or remarks.
